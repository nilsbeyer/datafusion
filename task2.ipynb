{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.nuscenes import NuScenes\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from celluloid import Camera\n",
    "from pyquaternion import Quaternion\n",
    "from nuscenes.utils.data_classes import LidarPointCloud\n",
    "from nuscenes.utils.geometry_utils import view_points\n",
    "\n",
    "mpl.rc('figure', max_open_warning = 0)\n",
    "%matplotlib inline\n",
    "\n",
    "nusc = NuScenes(version='v1.0-mini', dataroot='./data/nusc', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_instance = nusc.instance[599]\n",
    "ann_tokens = nusc.field2token('sample_annotation', 'instance_token', one_instance['token'])\n",
    "print(\"There are\", len(ann_tokens), \"annotations for instance 599\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lidar_pointcloud(sample_token):\n",
    "    sample_record = nusc.get('sample', sample_token)\n",
    "    pointsensor_channel = 'LIDAR_TOP'\n",
    "    pointsensor_token = sample_record['data'][pointsensor_channel]\n",
    "    pointsensor = nusc.get('sample_data', pointsensor_token)\n",
    "    pcl_path = nusc.get('sample_data', pointsensor_token)['filename']\n",
    "    pc =LidarPointCloud.from_file(os.path.join('./data/nusc',pcl_path))\n",
    "    return pointsensor_token, pc.points\n",
    "def rotate_pointcloud(cloud, quaternion):\n",
    "    def rot(an_array):\n",
    "        return quaternion.rotate(an_array)\n",
    "    return np.array(list(map(rot, cloud)))\n",
    "def visualize_absolute(ax, absolute_points, ego_pose, van_translation, relativeboxvectors):\n",
    "    #plt.axis('equal')\n",
    "    axes = plt.gca()\n",
    "    #axes.set_xlim([xmin,xmax])\n",
    "    #axes.set_ylim([ymin,ymax])\n",
    "    #ax.set(xlim=(300, 500), ylim=(1100, 1300))\n",
    "    return ax.scatter(absolute_points[0], absolute_points[1], c='red', s=0.3), ax.scatter(ego_pose['translation'][0], ego_pose['translation'][1]),ax.plot([van_translation[0] + relativeboxvector[0] for relativeboxvector in relativeboxvectors], [van_translation[1] + relativeboxvector[1] for relativeboxvector in relativeboxvectors])[0]\n",
    "def create_bounding_box(annotation_token):\n",
    "    '''\n",
    "    creates bounding box used for plotting\n",
    "    '''\n",
    "    van_annotation = nusc.get('sample_annotation', annotation_token)\n",
    "    relativeboxvectors = [(van_annotation['size'][1]/2,van_annotation['size'][0]/2, 0),\n",
    "                         (-van_annotation['size'][1]/2,van_annotation['size'][0]/2, 0),\n",
    "                         (-van_annotation['size'][1]/2,-van_annotation['size'][0]/2, 0),\n",
    "                         (van_annotation['size'][1]/2,-van_annotation['size'][0]/2, 0),\n",
    "                         (van_annotation['size'][1]/2,van_annotation['size'][0]/2, 0)]\n",
    "    return np.array(relativeboxvectors), van_annotation['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = []\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)  # fig and axes created once\n",
    "frontimages = []\n",
    "points2D = []\n",
    "time_ls = []\n",
    "\n",
    "# Display points and bounding box in global coordinates over whole scene\n",
    "for i,current_van_annotation_token in enumerate(ann_tokens):\n",
    "\n",
    "    # filter out points outside bounding box\n",
    "\n",
    "\n",
    "    ## Grab the data\n",
    "\n",
    "    van_annotation = nusc.get('sample_annotation', current_van_annotation_token)\n",
    "\n",
    "    #get respective frame token\n",
    "    sample_token = van_annotation['sample_token']\n",
    "    sample = nusc.get('sample', sample_token)\n",
    "    time_ls.append(sample['timestamp'])\n",
    "\n",
    "    pointsensor_token, points = get_lidar_pointcloud(sample_token)\n",
    "    calibrated_sensor_token = nusc.get('sample_data', pointsensor_token)['calibrated_sensor_token']\n",
    "    calibrated_sensor = nusc.get('calibrated_sensor', calibrated_sensor_token)\n",
    "    ego_pose = nusc.get('ego_pose', nusc.get('sample_data', pointsensor_token)['ego_pose_token'])\n",
    "\n",
    "    ## translate points to global reference frame\n",
    "\n",
    "    ### Rotate points around sensor and ego rotation\n",
    "\n",
    "    pointsensor_quaternion = Quaternion(calibrated_sensor['rotation'])\n",
    "    ego_quaternion = Quaternion(ego_pose['rotation'])\n",
    "\n",
    "    sensor_rotated_points = np.dot(pointsensor_quaternion.rotation_matrix, points[:3,:])\n",
    "    rotated_points = np.dot(ego_quaternion.rotation_matrix, sensor_rotated_points)\n",
    "\n",
    "    # use broadcasting to add translation to x and y dimension\n",
    "    absolute_points = rotated_points+np.array(ego_pose['translation'][:3]).reshape(-1,1)\n",
    "\n",
    "\n",
    "    ### rotate points by inverse bounding box rotation (translation to its reference frame unnecessary for only filtering)\n",
    "    reverse_van_quaternion = Quaternion(w=-1*van_annotation['rotation'][0], x=van_annotation['rotation'][1], y=van_annotation['rotation'][2], z=van_annotation['rotation'][3])\n",
    "    points_bounding_rotation = np.dot(reverse_van_quaternion.rotation_matrix, absolute_points)\n",
    "\n",
    "    #new stuff\n",
    "    relativeboxvectors, position = create_bounding_box(current_van_annotation_token)\n",
    "\n",
    "    rotated_box = relativeboxvectors+reverse_van_quaternion.rotate(position)\n",
    "\n",
    "    x_max = rotated_box[:,0].max()\n",
    "    x_min = rotated_box[:,0].min()\n",
    "\n",
    "    y_max = rotated_box[:,1].max()\n",
    "    y_min = rotated_box[:,1].min()\n",
    "\n",
    "    ## Remove points that are outside the bounding box\n",
    "    mask = np.ones(points_bounding_rotation.shape[1], dtype=bool)\n",
    "\n",
    "    mask = np.logical_and(mask, points_bounding_rotation[0] > x_min)\n",
    "    mask = np.logical_and(mask, points_bounding_rotation[0] < x_max)\n",
    "\n",
    "    mask = np.logical_and(mask, points_bounding_rotation[1] > y_min)\n",
    "    mask = np.logical_and(mask, points_bounding_rotation[1] < y_max)\n",
    "\n",
    "    points_filtered_rotated = points_bounding_rotation[:,mask]\n",
    "\n",
    "    ### rotate points back\n",
    "\n",
    "    van_quaternion = Quaternion(van_annotation['rotation'])\n",
    "    points_filtered_absolute = np.dot(van_quaternion.rotation_matrix, points_filtered_rotated)\n",
    "    points2D.append(points_filtered_absolute[0:2, :])\n",
    "    # append list of plots to movie\n",
    "    rotated_relativeboxvectors = rotate_pointcloud(relativeboxvectors, van_quaternion)\n",
    "    plotlist = visualize_absolute(ax, points_filtered_absolute, ego_pose, van_annotation['translation'], rotated_relativeboxvectors)\n",
    "\n",
    "    ims.append(plotlist)     \n",
    "\n",
    "ax.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = mpl.animation.ArtistAnimation(fig, ims, repeat=False)\n",
    "ani.save('test.gif', writer='pillow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([])\n",
    "Y = np.array([])\n",
    "for i in range(len(points2D)):\n",
    "    X = np.append(X, points2D[i][0])\n",
    "    Y = np.append(Y, points2D[i][1])\n",
    "plt.scatter(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_arr = np.array([]).reshape(0, 2)\n",
    "for i in range(len(points2D)):\n",
    "    temp = np.mean(points2D[i], axis=1).reshape(1,2)\n",
    "    mean_arr = np.append(mean_arr, temp, axis=0)\n",
    "print(mean_arr)\n",
    "print(time_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_filter(sigma, C_00, R):\n",
    "    C_kk = C_00\n",
    "    X_data = np.array(mean_arr[0][0])\n",
    "    y_data = np.array(mean_arr[0][1])\n",
    "    for k in range(len(points2D)-1):\n",
    "        datatime1 = datetime.fromtimestamp(int(time_ls[k])/1e6)\n",
    "        datatime2 = datetime.fromtimestamp(int(time_ls[k+1])/1e6)\n",
    "        t = (datatime2 - datatime1).microseconds/1e6\n",
    "        F = np.identity(4)\n",
    "        F[0, 2] = t\n",
    "        F[1, 3] = t\n",
    "\n",
    "        velocity = (mean_arr[k+1] - mean_arr[k]) / t\n",
    "        x_kk = np.array([mean_arr[k][0], mean_arr[k][1], velocity[0], velocity[1]]).reshape(4, 1)\n",
    "        x_k1k = F.dot(x_kk)\n",
    "\n",
    "        term = np.array([0.5*t_init*t_init, 0.5*t_init*t_init, t_init, t_init]).reshape(4, 1)\n",
    "        Q = term.dot(sigma).dot(term.T)\n",
    "        C_k1k = F.dot(C_kk).dot(F.T) + Q\n",
    "\n",
    "        H = np.zeros((2, 4))\n",
    "        H[0, 0] = 1\n",
    "        H[1, 1] = 1\n",
    "        y_k1 = H.dot(x_k1k)\n",
    "\n",
    "        S = H.dot(C_k1k).dot(H.T) + R\n",
    "        K = C_k1k.dot(H.T).dot(np.linalg.inv(S))\n",
    "        x_k1k1 = x_k1k + K.dot(y_k1 - H.dot(x_k1k))\n",
    "        # update C_kk\n",
    "        C_kk = C_k1k - K.dot(S).dot(K.T)\n",
    "        X_data = np.append(X_data, x_k1k1[0][0])\n",
    "        y_data = np.append(y_data, x_k1k1[1][0])\n",
    "    return X_data, y_data\n",
    "sigma = np.array([1]).reshape(1, 1)\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "x=np.random.normal(size=4)\n",
    "y=np.random.normal(size=4)\n",
    "C_00 = np.cov(np.vstack((x, y)).T)\n",
    "\n",
    "x=np.random.normal(size=2)\n",
    "y=np.random.normal(size=2)\n",
    "R = np.cov(np.vstack((x, y)).T)\n",
    "X_data, y_data = kalman_filter(sigma, C_00, R)\n",
    "plt.scatter(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
