{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.nuscenes import NuScenes\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import numpy as np\n",
    "from celluloid import Camera\n",
    "from pyquaternion import Quaternion\n",
    "from nuscenes.utils.data_classes import LidarPointCloud\n",
    "\n",
    "mpl.rc('figure', max_open_warning = 0)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc = NuScenes(version='v1.0-mini', dataroot='./data/nusc', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sample = nusc.sample[0]\n",
    "sample_data = nusc.get('sample_data', my_sample['data']['LIDAR_TOP'])\n",
    "pcl_path = sample_data['filename']\n",
    "nusc.render_sample_data(sample_data['token'])\n",
    "pc =LidarPointCloud.from_file(os.path.join('./data/nusc',pcl_path))\n",
    "color = pc.points[3] / np.max(pc.points[3])\n",
    "plt.scatter(pc.points[0], pc.points[1], c=color, alpha=0.2, s=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pc.points[0:2].T\n",
    "kmeans = KMeans(n_clusters=69)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=0.2, cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=40, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lidar_pointcloud(sample_token):\n",
    "    sample_record = nusc.get('sample', sample_token)\n",
    "    pointsensor_channel = 'LIDAR_TOP'\n",
    "    pointsensor_token = sample_record['data'][pointsensor_channel]\n",
    "    pointsensor = nusc.get('sample_data', pointsensor_token)\n",
    "    pcl_path = nusc.get('sample_data', pointsensor_token)['filename']\n",
    "    pc =LidarPointCloud.from_file(os.path.join('./data/nusc',pcl_path))\n",
    "    return pointsensor_token, pc.points\n",
    "def rotate_pointcloud(cloud, quaternion):\n",
    "    def rot(an_array):\n",
    "        return quaternion.rotate(an_array)\n",
    "    return np.array(list(map(rot, cloud)))\n",
    "def visualize_absolute(ax, absolute_points, ego_pose, van_translation, relativeboxvectors):\n",
    "    axes = plt.gca()\n",
    "    return ax.scatter(absolute_points[0], absolute_points[1], c='red', s=0.3), ax.scatter(ego_pose['translation'][0], ego_pose['translation'][1]),ax.plot([van_translation[0] + relativeboxvector[0] for relativeboxvector in relativeboxvectors], [van_translation[1] + relativeboxvector[1] for relativeboxvector in relativeboxvectors])[0]\n",
    "def create_bounding_box(annotation_token):\n",
    "    '''\n",
    "    creates bounding box used for plotting\n",
    "    '''\n",
    "    van_annotation = nusc.get('sample_annotation', annotation_token)\n",
    "    relativeboxvectors = [(van_annotation['size'][1]/2,van_annotation['size'][0]/2, 0),\n",
    "                         (-van_annotation['size'][1]/2,van_annotation['size'][0]/2, 0),\n",
    "                         (-van_annotation['size'][1]/2,-van_annotation['size'][0]/2, 0),\n",
    "                         (van_annotation['size'][1]/2,-van_annotation['size'][0]/2, 0),\n",
    "                         (van_annotation['size'][1]/2,van_annotation['size'][0]/2, 0)]\n",
    "    return np.array(relativeboxvectors), van_annotation['translation']\n",
    "cat_ls = ['vehicle.bicycle', 'vehicle.bus.bendy', 'vehicle.bus.rigid', 'vehicle.car', 'vehicle.construction'\n",
    "         'vehicle.motorcycle', 'vehicle.trailer', 'vehicle.truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterSample(sample):\n",
    "    ann_tokens = sample['anns']\n",
    "    X_data = np.array([])\n",
    "    y_data = np.array([])\n",
    "    valid_ann_num = 0\n",
    "    for i,current_van_annotation_token in enumerate(ann_tokens):\n",
    "        van_annotation = nusc.get('sample_annotation', current_van_annotation_token)\n",
    "        # Only track vehicles\n",
    "        if van_annotation['category_name'] not in cat_ls:\n",
    "            continue\n",
    "        pointsensor_token, points = get_lidar_pointcloud(sample['token'])\n",
    "        calibrated_sensor_token = nusc.get('sample_data', pointsensor_token)['calibrated_sensor_token']\n",
    "        calibrated_sensor = nusc.get('calibrated_sensor', calibrated_sensor_token)\n",
    "        ego_pose = nusc.get('ego_pose', nusc.get('sample_data', pointsensor_token)['ego_pose_token'])\n",
    "\n",
    "        ### Rotate points around sensor and ego rotation\n",
    "        pointsensor_quaternion = Quaternion(calibrated_sensor['rotation'])\n",
    "        ego_quaternion = Quaternion(ego_pose['rotation'])\n",
    "\n",
    "        sensor_rotated_points = np.dot(pointsensor_quaternion.rotation_matrix, points[:3,:])\n",
    "        rotated_points = np.dot(ego_quaternion.rotation_matrix, sensor_rotated_points)\n",
    "\n",
    "        # use broadcasting to add translation to x and y dimension\n",
    "        absolute_points = rotated_points+np.array(ego_pose['translation'][:3]).reshape(-1,1)\n",
    "\n",
    "        ### rotate points by inverse bounding box rotation (translation to its reference frame unnecessary for only filtering)\n",
    "        reverse_van_quaternion = Quaternion(w=-1*van_annotation['rotation'][0], x=van_annotation['rotation'][1], y=van_annotation['rotation'][2], z=van_annotation['rotation'][3])\n",
    "        points_bounding_rotation = np.dot(reverse_van_quaternion.rotation_matrix, absolute_points)\n",
    "\n",
    "        #new stuff\n",
    "        relativeboxvectors, position = create_bounding_box(current_van_annotation_token)\n",
    "        rotated_box = relativeboxvectors+reverse_van_quaternion.rotate(position)\n",
    "        x_max = rotated_box[:,0].max()\n",
    "        x_min = rotated_box[:,0].min()\n",
    "        y_max = rotated_box[:,1].max()\n",
    "        y_min = rotated_box[:,1].min()\n",
    "\n",
    "        ## Remove points that are outside the bounding box\n",
    "        mask = np.ones(points_bounding_rotation.shape[1], dtype=bool)\n",
    "        mask = np.logical_and(mask, points_bounding_rotation[0] > x_min)\n",
    "        mask = np.logical_and(mask, points_bounding_rotation[0] < x_max)\n",
    "        mask = np.logical_and(mask, points_bounding_rotation[1] > y_min)\n",
    "        mask = np.logical_and(mask, points_bounding_rotation[1] < y_max)\n",
    "        points_filtered_rotated = points_bounding_rotation[:,mask]\n",
    "\n",
    "        ### rotate points back\n",
    "        van_quaternion = Quaternion(van_annotation['rotation'])\n",
    "        points_filtered_absolute = np.dot(van_quaternion.rotation_matrix, points_filtered_rotated)\n",
    "        if (points_filtered_absolute.size != 0):\n",
    "            valid_ann_num = valid_ann_num + 1\n",
    "            for px in points_filtered_absolute[0]:\n",
    "                X_data = np.append(X_data, px)\n",
    "            for py in points_filtered_absolute[1]:\n",
    "                y_data = np.append(y_data, py)\n",
    "    X_data = np.reshape(X_data, (X_data.shape[0], 1))\n",
    "    y_data = np.reshape(y_data, (y_data.shape[0], 1))\n",
    "    data = np.append(X_data, y_data, axis=1)\n",
    "    # Implement K-means\n",
    "    kmeans = KMeans(n_clusters=valid_ann_num)\n",
    "    kmeans.fit(data)\n",
    "    y_kmeans = kmeans.predict(data)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    # Implement DBSCAN\n",
    "    clustering = DBSCAN(eps=3, min_samples=2).fit(data)\n",
    "    labels = clustering.labels_\n",
    "    return data, centers, y_kmeans, labels\n",
    "\n",
    "# Plot\n",
    "data, centers, y_kmeans, labels = clusterSample(my_sample)\n",
    "plt.scatter(data[:, 0], data[:, 1], c=y_kmeans, s=1, cmap='viridis')\n",
    "plt.title('Origin')\n",
    "plt.show()\n",
    "plt.scatter(data[:, 0], data[:, 1], c=y_kmeans, s=1, cmap='viridis')\n",
    "\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=40, alpha=0.6)\n",
    "plt.title('With K-Means')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(data[:, 0], data[:, 1], c=labels, s=1, cmap='viridis')\n",
    "plt.title('With DBSCAN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scene = nusc.scene[0]\n",
    "sample = nusc.get('sample', my_scene['first_sample_token'])\n",
    "sample_ls = []\n",
    "sample_ls.append(sample)\n",
    "while(sample['next'] != ''):\n",
    "    sample = nusc.get('sample', sample['next'])\n",
    "    sample_ls.append(sample)\n",
    "    \n",
    "# Create movie using kmeans\n",
    "fig = plt.figure()\n",
    "camera = Camera(plt.figure())\n",
    "\n",
    "for curr_sample in sample_ls:\n",
    "    data, centers, y_kmeans, _ = clusterSample(curr_sample)\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=y_kmeans, s=1, cmap='viridis')\n",
    "    plt.scatter(centers[:, 0], centers[:, 1], c='black', s=40, alpha=0.6)\n",
    "    camera.snap()\n",
    "    \n",
    "anim = camera.animate(blit=True)\n",
    "anim.save(\"kmeans.gif\", writer='pillow')\n",
    "\n",
    "# Create movie using dbscan\n",
    "fig = plt.figure()\n",
    "camera = Camera(plt.figure())\n",
    "\n",
    "for curr_sample in sample_ls:\n",
    "    data, _, _, labels = clusterSample(curr_sample)\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=labels, s=1, cmap='viridis')\n",
    "    camera.snap()\n",
    "    \n",
    "anim = camera.animate(blit=True)\n",
    "anim.save(\"dbscan.gif\", writer='pillow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "def getPoints(sample):\n",
    "    ann_tokens = sample['anns']\n",
    "    points2D = []\n",
    "    valid_ann_num = 0\n",
    "    for i,current_van_annotation_token in enumerate(ann_tokens):\n",
    "        van_annotation = nusc.get('sample_annotation', current_van_annotation_token)\n",
    "        # Only track vehicles\n",
    "        if van_annotation['category_name'] not in cat_ls:\n",
    "            continue\n",
    "        valid_ann_num = valid_ann_num + 1\n",
    "        pointsensor_token, points = get_lidar_pointcloud(sample['token'])\n",
    "        calibrated_sensor_token = nusc.get('sample_data', pointsensor_token)['calibrated_sensor_token']\n",
    "        calibrated_sensor = nusc.get('calibrated_sensor', calibrated_sensor_token)\n",
    "        ego_pose = nusc.get('ego_pose', nusc.get('sample_data', pointsensor_token)['ego_pose_token'])\n",
    "\n",
    "        ### Rotate points around sensor and ego rotation\n",
    "        pointsensor_quaternion = Quaternion(calibrated_sensor['rotation'])\n",
    "        ego_quaternion = Quaternion(ego_pose['rotation'])\n",
    "\n",
    "        sensor_rotated_points = np.dot(pointsensor_quaternion.rotation_matrix, points[:3,:])\n",
    "        rotated_points = np.dot(ego_quaternion.rotation_matrix, sensor_rotated_points)\n",
    "\n",
    "        # use broadcasting to add translation to x and y dimension\n",
    "        absolute_points = rotated_points+np.array(ego_pose['translation'][:3]).reshape(-1,1)\n",
    "\n",
    "        ### rotate points by inverse bounding box rotation (translation to its reference frame unnecessary for only filtering)\n",
    "        reverse_van_quaternion = Quaternion(w=-1*van_annotation['rotation'][0], x=van_annotation['rotation'][1], y=van_annotation['rotation'][2], z=van_annotation['rotation'][3])\n",
    "        points_bounding_rotation = np.dot(reverse_van_quaternion.rotation_matrix, absolute_points)\n",
    "\n",
    "        #new stuff\n",
    "        relativeboxvectors, position = create_bounding_box(current_van_annotation_token)\n",
    "        rotated_box = relativeboxvectors+reverse_van_quaternion.rotate(position)\n",
    "        x_max = rotated_box[:,0].max()\n",
    "        x_min = rotated_box[:,0].min()\n",
    "        y_max = rotated_box[:,1].max()\n",
    "        y_min = rotated_box[:,1].min()\n",
    "\n",
    "        ## Remove points that are outside the bounding box\n",
    "        mask = np.ones(points_bounding_rotation.shape[1], dtype=bool)\n",
    "        mask = np.logical_and(mask, points_bounding_rotation[0] > x_min)\n",
    "        mask = np.logical_and(mask, points_bounding_rotation[0] < x_max)\n",
    "        mask = np.logical_and(mask, points_bounding_rotation[1] > y_min)\n",
    "        mask = np.logical_and(mask, points_bounding_rotation[1] < y_max)\n",
    "        \n",
    "        points_filtered_rotated = points_bounding_rotation[:,mask]\n",
    "        \n",
    "        van_quaternion = Quaternion(van_annotation['rotation'])\n",
    "        points_filtered_absolute = np.dot(van_quaternion.rotation_matrix, points_filtered_rotated)\n",
    "        if points_filtered_absolute.size != 0:\n",
    "            points2D.append(points_filtered_absolute[0:2, :])\n",
    "    return points2D\n",
    "        \n",
    "mean_arr_ls = []\n",
    "for curr_sample in sample_ls:\n",
    "    points2D = getPoints(curr_sample)\n",
    "    mean_arr = np.array([]).reshape(0, 2)\n",
    "    for i in range(len(points2D)):\n",
    "        if not np.isnan(np.min(temp)):\n",
    "            mean_arr = np.append(mean_arr, temp, axis=0)\n",
    "    mean_arr_ls.append(mean_arr)\n",
    "print(len(mean_arr_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
