{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.nuscenes import NuScenes\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from celluloid import Camera\n",
    "from pyquaternion import Quaternion\n",
    "from nuscenes.utils.data_classes import LidarPointCloud\n",
    "\n",
    "mpl.rc('figure', max_open_warning = 0)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc = NuScenes(version='v1.0-mini', dataroot='./data/nusc', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sample = nusc.sample[0]\n",
    "sample_data = nusc.get('sample_data', my_sample['data']['LIDAR_TOP'])\n",
    "pcl_path = sample_data['filename']\n",
    "nusc.render_sample_data(sample_data['token'])\n",
    "pc =LidarPointCloud.from_file(os.path.join('./data/nusc',pcl_path))\n",
    "color = pc.points[3] / np.max(pc.points[3])\n",
    "plt.scatter(pc.points[0], pc.points[1], c=color, alpha=0.2, s=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pc.points[0:2].T\n",
    "kmeans = KMeans(n_clusters=69)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=0.2, cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=40, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lidar_pointcloud(sample_token):\n",
    "    sample_record = nusc.get('sample', sample_token)\n",
    "    pointsensor_channel = 'LIDAR_TOP'\n",
    "    pointsensor_token = sample_record['data'][pointsensor_channel]\n",
    "    pointsensor = nusc.get('sample_data', pointsensor_token)\n",
    "    pcl_path = nusc.get('sample_data', pointsensor_token)['filename']\n",
    "    pc =LidarPointCloud.from_file(os.path.join('./data/nusc',pcl_path))\n",
    "    return pointsensor_token, pc.points\n",
    "def rotate_pointcloud(cloud, quaternion):\n",
    "    def rot(an_array):\n",
    "        return quaternion.rotate(an_array)\n",
    "    return np.array(list(map(rot, cloud)))\n",
    "def visualize_absolute(ax, absolute_points, ego_pose, van_translation, relativeboxvectors):\n",
    "    axes = plt.gca()\n",
    "    return ax.scatter(absolute_points[0], absolute_points[1], c='red', s=0.3), ax.scatter(ego_pose['translation'][0], ego_pose['translation'][1]),ax.plot([van_translation[0] + relativeboxvector[0] for relativeboxvector in relativeboxvectors], [van_translation[1] + relativeboxvector[1] for relativeboxvector in relativeboxvectors])[0]\n",
    "def create_bounding_box(annotation_token):\n",
    "    '''\n",
    "    creates bounding box used for plotting\n",
    "    '''\n",
    "    van_annotation = nusc.get('sample_annotation', annotation_token)\n",
    "    relativeboxvectors = [(van_annotation['size'][1]/2,van_annotation['size'][0]/2, 0),\n",
    "                         (-van_annotation['size'][1]/2,van_annotation['size'][0]/2, 0),\n",
    "                         (-van_annotation['size'][1]/2,-van_annotation['size'][0]/2, 0),\n",
    "                         (van_annotation['size'][1]/2,-van_annotation['size'][0]/2, 0),\n",
    "                         (van_annotation['size'][1]/2,van_annotation['size'][0]/2, 0)]\n",
    "    return np.array(relativeboxvectors), van_annotation['translation']\n",
    "cat_ls = ['vehicle.bicycle', 'vehicle.bus.bendy', 'vehicle.bus.rigid', 'vehicle.car', 'vehicle.construction'\n",
    "         'vehicle.motorcycle', 'vehicle.trailer', 'vehicle.truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterSample(sample):\n",
    "    ann_tokens = sample['anns']\n",
    "    X_data = np.array([])\n",
    "    y_data = np.array([])\n",
    "    valid_ann_num = 0\n",
    "    for i,current_van_annotation_token in enumerate(ann_tokens):\n",
    "        van_annotation = nusc.get('sample_annotation', current_van_annotation_token)\n",
    "        # Only track vehicles\n",
    "        if van_annotation['category_name'] not in cat_ls:\n",
    "            continue\n",
    "        pointsensor_token, points = get_lidar_pointcloud(sample['token'])\n",
    "        calibrated_sensor_token = nusc.get('sample_data', pointsensor_token)['calibrated_sensor_token']\n",
    "        calibrated_sensor = nusc.get('calibrated_sensor', calibrated_sensor_token)\n",
    "        ego_pose = nusc.get('ego_pose', nusc.get('sample_data', pointsensor_token)['ego_pose_token'])\n",
    "\n",
    "        ### Rotate points around sensor and ego rotation\n",
    "        pointsensor_quaternion = Quaternion(calibrated_sensor['rotation'])\n",
    "        ego_quaternion = Quaternion(ego_pose['rotation'])\n",
    "\n",
    "        sensor_rotated_points = np.dot(pointsensor_quaternion.rotation_matrix, points[:3,:])\n",
    "        rotated_points = np.dot(ego_quaternion.rotation_matrix, sensor_rotated_points)\n",
    "\n",
    "        # use broadcasting to add translation to x and y dimension\n",
    "        absolute_points = rotated_points+np.array(ego_pose['translation'][:3]).reshape(-1,1)\n",
    "\n",
    "        ### rotate points by inverse bounding box rotation (translation to its reference frame unnecessary for only filtering)\n",
    "        reverse_van_quaternion = Quaternion(w=-1*van_annotation['rotation'][0], x=van_annotation['rotation'][1], y=van_annotation['rotation'][2], z=van_annotation['rotation'][3])\n",
    "        points_bounding_rotation = np.dot(reverse_van_quaternion.rotation_matrix, absolute_points)\n",
    "\n",
    "        #new stuff\n",
    "        relativeboxvectors, position = create_bounding_box(current_van_annotation_token)\n",
    "        rotated_box = relativeboxvectors+reverse_van_quaternion.rotate(position)\n",
    "        x_max = rotated_box[:,0].max()\n",
    "        x_min = rotated_box[:,0].min()\n",
    "        y_max = rotated_box[:,1].max()\n",
    "        y_min = rotated_box[:,1].min()\n",
    "\n",
    "        ## Remove points that are outside the bounding box\n",
    "        mask = np.ones(points_bounding_rotation.shape[1], dtype=bool)\n",
    "        mask = np.logical_and(mask, points_bounding_rotation[0] > x_min)\n",
    "        mask = np.logical_and(mask, points_bounding_rotation[0] < x_max)\n",
    "        mask = np.logical_and(mask, points_bounding_rotation[1] > y_min)\n",
    "        mask = np.logical_and(mask, points_bounding_rotation[1] < y_max)\n",
    "        points_filtered_rotated = points_bounding_rotation[:,mask]\n",
    "\n",
    "        ### rotate points back\n",
    "        van_quaternion = Quaternion(van_annotation['rotation'])\n",
    "        points_filtered_absolute = np.dot(van_quaternion.rotation_matrix, points_filtered_rotated)\n",
    "        if (points_filtered_absolute.size != 0):\n",
    "            valid_ann_num = valid_ann_num + 1\n",
    "            for px in points_filtered_absolute[0]:\n",
    "                X_data = np.append(X_data, px)\n",
    "            for py in points_filtered_absolute[1]:\n",
    "                y_data = np.append(y_data, py)\n",
    "    X_data = np.reshape(X_data, (X_data.shape[0], 1))\n",
    "    y_data = np.reshape(y_data, (y_data.shape[0], 1))\n",
    "    data = np.append(X_data, y_data, axis=1)\n",
    "    # Implement K-means\n",
    "    kmeans = KMeans(n_clusters=valid_ann_num)\n",
    "    kmeans.fit(data)\n",
    "    y_kmeans = kmeans.predict(data)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    # Implement DBSCAN\n",
    "    clustering = DBSCAN(eps=3, min_samples=2).fit(data)\n",
    "    labels = clustering.labels_\n",
    "    return data, centers, y_kmeans, labels\n",
    "\n",
    "# Plot\n",
    "data, centers, y_kmeans, labels = clusterSample(my_sample)\n",
    "plt.scatter(data[:, 0], data[:, 1], c=y_kmeans, s=1, cmap='viridis')\n",
    "plt.title('Origin')\n",
    "plt.show()\n",
    "plt.scatter(data[:, 0], data[:, 1], c=y_kmeans, s=1, cmap='viridis')\n",
    "\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=40, alpha=0.6)\n",
    "plt.title('With K-Means')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(data[:, 0], data[:, 1], c=labels, s=1, cmap='viridis')\n",
    "plt.title('With DBSCAN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scene = nusc.scene[0]\n",
    "sample = nusc.get('sample', my_scene['first_sample_token'])\n",
    "sample_ls = []\n",
    "sample_ls.append(sample)\n",
    "while(sample['next'] != ''):\n",
    "    sample = nusc.get('sample', sample['next'])\n",
    "    sample_ls.append(sample)\n",
    "    \n",
    "# Create movie using kmeans\n",
    "fig = plt.figure()\n",
    "camera = Camera(plt.figure())\n",
    "\n",
    "for curr_sample in sample_ls:\n",
    "    data, centers, y_kmeans, _ = clusterSample(curr_sample)\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=y_kmeans, s=1, cmap='viridis')\n",
    "    plt.scatter(centers[:, 0], centers[:, 1], c='black', s=40, alpha=0.6)\n",
    "    camera.snap()\n",
    "    \n",
    "anim = camera.animate(blit=True)\n",
    "anim.save(\"kmeans.gif\", writer='pillow')\n",
    "\n",
    "# Create movie using dbscan\n",
    "fig = plt.figure()\n",
    "camera = Camera(plt.figure())\n",
    "\n",
    "for curr_sample in sample_ls:\n",
    "    data, _, _, labels = clusterSample(curr_sample)\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=labels, s=1, cmap='viridis')\n",
    "    camera.snap()\n",
    "    \n",
    "anim = camera.animate(blit=True)\n",
    "anim.save(\"dbscan.gif\", writer='pillow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPoints(sample):\n",
    "    ann_tokens = sample['anns']\n",
    "    points2D = []\n",
    "    valid_ann_num = 0\n",
    "    for i,current_van_annotation_token in enumerate(ann_tokens):\n",
    "        van_annotation = nusc.get('sample_annotation', current_van_annotation_token)\n",
    "        # Only track vehicles\n",
    "        if van_annotation['category_name'] not in cat_ls:\n",
    "            continue\n",
    "        valid_ann_num = valid_ann_num + 1\n",
    "        pointsensor_token, points = get_lidar_pointcloud(sample['token'])\n",
    "        calibrated_sensor_token = nusc.get('sample_data', pointsensor_token)['calibrated_sensor_token']\n",
    "        calibrated_sensor = nusc.get('calibrated_sensor', calibrated_sensor_token)\n",
    "        ego_pose = nusc.get('ego_pose', nusc.get('sample_data', pointsensor_token)['ego_pose_token'])\n",
    "\n",
    "        ### Rotate points around sensor and ego rotation\n",
    "        pointsensor_quaternion = Quaternion(calibrated_sensor['rotation'])\n",
    "        ego_quaternion = Quaternion(ego_pose['rotation'])\n",
    "\n",
    "        sensor_rotated_points = np.dot(pointsensor_quaternion.rotation_matrix, points[:3,:])\n",
    "        rotated_points = np.dot(ego_quaternion.rotation_matrix, sensor_rotated_points)\n",
    "\n",
    "        # use broadcasting to add translation to x and y dimension\n",
    "        absolute_points = rotated_points+np.array(ego_pose['translation'][:3]).reshape(-1,1)\n",
    "\n",
    "        ### rotate points by inverse bounding box rotation (translation to its reference frame unnecessary for only filtering)\n",
    "        reverse_van_quaternion = Quaternion(w=-1*van_annotation['rotation'][0], x=van_annotation['rotation'][1], y=van_annotation['rotation'][2], z=van_annotation['rotation'][3])\n",
    "        points_bounding_rotation = np.dot(reverse_van_quaternion.rotation_matrix, absolute_points)\n",
    "\n",
    "        #new stuff\n",
    "        relativeboxvectors, position = create_bounding_box(current_van_annotation_token)\n",
    "        rotated_box = relativeboxvectors+reverse_van_quaternion.rotate(position)\n",
    "        x_max = rotated_box[:,0].max()\n",
    "        x_min = rotated_box[:,0].min()\n",
    "        y_max = rotated_box[:,1].max()\n",
    "        y_min = rotated_box[:,1].min()\n",
    "\n",
    "        ## Remove points that are outside the bounding box\n",
    "        mask = np.ones(points_bounding_rotation.shape[1], dtype=bool)\n",
    "        mask = np.logical_and(mask, points_bounding_rotation[0] > x_min)\n",
    "        mask = np.logical_and(mask, points_bounding_rotation[0] < x_max)\n",
    "        mask = np.logical_and(mask, points_bounding_rotation[1] > y_min)\n",
    "        mask = np.logical_and(mask, points_bounding_rotation[1] < y_max)\n",
    "        \n",
    "        points_filtered_rotated = points_bounding_rotation[:,mask]\n",
    "        \n",
    "        van_quaternion = Quaternion(van_annotation['rotation'])\n",
    "        points_filtered_absolute = np.dot(van_quaternion.rotation_matrix, points_filtered_rotated)\n",
    "        if points_filtered_absolute.size != 0:\n",
    "            points2D.append(points_filtered_absolute[0:2, :])\n",
    "    return points2D\n",
    "        \n",
    "mean_arr_ls = []\n",
    "time_ls = []\n",
    "for curr_sample in sample_ls:\n",
    "    points2D = getPoints(curr_sample)\n",
    "    time_ls.append(curr_sample['timestamp'])\n",
    "    mean_arr = np.array([]).reshape(0, 2)\n",
    "    for i in range(len(points2D)):\n",
    "        temp = np.mean(points2D[i], axis=1).reshape(1,2)\n",
    "        if not np.isnan(np.min(temp)):\n",
    "            mean_arr = np.append(mean_arr, temp, axis=0)\n",
    "    mean_arr_ls.append(mean_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_00 = 1*np.eye(4)\n",
    "sigma = 0.01\n",
    "r = 0.01\n",
    "R = np.array(((r,0),(0,r)))\n",
    "C_kk = C_00\n",
    "\n",
    "\n",
    "for s in range(len(mean_arr_ls)-1):\n",
    "    cost_mat = np.zeros((mean_arr_ls[s].shape[0], mean_arr_ls[s+1].shape[0]))\n",
    "    for i in range(mean_arr_ls[s].shape[0]):\n",
    "        for j in range(mean_arr_ls[s+1].shape[0]):\n",
    "            cost_mat[i][j] = np.linalg.norm(mean_arr_ls[s][i]-mean_arr_ls[s+1][j])\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_mat)\n",
    "    # print('cost matrix shape:', cost_mat.shape)\n",
    "    # print(cost_mat)\n",
    "    # print('row', row_ind)\n",
    "    # print('col', col_ind)\n",
    "    # print('cost sum:', cost_mat[row_ind, col_ind].sum())\n",
    "    X_curr = mean_arr_ls[s][row_ind][:, 0]\n",
    "    y_curr = mean_arr_ls[s][row_ind][:, 1]\n",
    "    X_next = mean_arr_ls[s+1][col_ind][:, 0]\n",
    "    y_next = mean_arr_ls[s+1][col_ind][:, 1]\n",
    "    \n",
    "    if s == 0:\n",
    "        num_veh = X_curr.shape[0]\n",
    "        X_data, y_data = X_curr.reshape(num_veh, 1), y_curr.reshape(num_veh, 1)\n",
    "    if np.minimum(mean_arr_ls[s].shape[0], mean_arr_ls[s+1].shape[0]) < num_veh:\n",
    "        continue\n",
    "    X_data_new, y_data_new = np.zeros((num_veh, 1)), np.zeros((num_veh, 1))\n",
    "    for i in range(num_veh):\n",
    "        datatime1 = datetime.fromtimestamp(int(time_ls[s])/1e6)\n",
    "        datatime2 = datetime.fromtimestamp(int(time_ls[s+1])/1e6)\n",
    "        t = (datatime2 - datatime1).microseconds/1e6\n",
    "        F = np.identity(4)\n",
    "        F[0, 2] = t\n",
    "        F[1, 3] = t\n",
    "        velocity_x = (X_next[i] - X_curr[i]) / t\n",
    "        velocity_y = (y_next[i] - y_curr[i]) / t\n",
    "        x_kk = np.array([X_next[i], y_next[i], velocity_x, velocity_y]).reshape(4, 1)\n",
    "        x_k1k = F.dot(x_kk)\n",
    "\n",
    "        term = np.array([0.5*t*t, 0.5*t*t, t, t]).reshape(4, 1)\n",
    "        Q = term.dot(sigma).dot(term.T)\n",
    "        C_k1k = F.dot(C_kk).dot(F.T) + Q\n",
    "\n",
    "        H = np.zeros((2, 4))\n",
    "        H[0, 0] = 1\n",
    "        H[1, 1] = 1\n",
    "        y_k1 = np.array([X_curr[i], y_curr[i]]).reshape(2, 1)\n",
    "\n",
    "        S = H.dot(C_k1k).dot(H.T) + R\n",
    "        K = C_k1k.dot(H.T).dot(np.linalg.inv(S))\n",
    "        x_k1k1 = x_k1k + K.dot(y_k1 - H.dot(x_k1k))\n",
    "        # update C_kk\n",
    "        C_kk = C_k1k - K.dot(S).dot(K.T)\n",
    "        X_data_new[i] = x_k1k1[0]\n",
    "        y_data_new[i] = x_k1k1[1]\n",
    "    X_data = np.append(X_data, X_data_new, axis=1)\n",
    "    y_data = np.append(y_data, y_data_new, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "camera = Camera(plt.figure())\n",
    "\n",
    "for i in range(X_data.shape[1]):\n",
    "    plt.scatter(X_data[0, i], y_data[0, i], c='k')\n",
    "    plt.scatter(X_data[1, i], y_data[1, i], c='b')\n",
    "    plt.scatter(X_data[2, i], y_data[2, i], c='r')\n",
    "    plt.scatter(X_data[3, i], y_data[3, i], c='y')\n",
    "    camera.snap()\n",
    "anim = camera.animate(blit=True)\n",
    "anim.save(\"multiKalman.gif\", writer='pillow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the tracker works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "print(\"  Example1\")\n",
    "for i in range(3):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.scatter(X_data[0, i], y_data[0, i], c='k')\n",
    "    plt.scatter(X_data[1, i], y_data[1, i], c='b')\n",
    "    plt.scatter(X_data[2, i], y_data[2, i], c='r')\n",
    "    plt.scatter(X_data[3, i], y_data[3, i], c='y')\n",
    "plt.show()\n",
    "print(\"  Example2\")\n",
    "for i in range(11, 16):\n",
    "    plt.subplot(3, 2, i-10)\n",
    "    plt.scatter(X_data[0, i], y_data[0, i], c='k')\n",
    "    plt.scatter(X_data[1, i], y_data[1, i], c='b')\n",
    "    plt.scatter(X_data[2, i], y_data[2, i], c='r')\n",
    "    plt.scatter(X_data[3, i], y_data[3, i], c='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
